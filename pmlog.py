__version__ = (0, 0, 24)


# ‚ñÑ‚ñÄ‚ñà ‚ñà‚ñÑ ‚ñà ‚ñà‚ñÄ‚ñà ‚ñà‚ñÑ ‚ñà ‚ñà‚ñÄ‚ñà ‚ñÄ‚ñÄ‚ñà ‚ñà‚ñÄ‚ñà ‚ñà ‚ñà ‚ñà‚ñÄ
# ‚ñà‚ñÄ‚ñà ‚ñà ‚ñÄ‚ñà ‚ñà‚ñÑ‚ñà ‚ñà ‚ñÄ‚ñà ‚ñÄ‚ñÄ‚ñà   ‚ñà ‚ñÄ‚ñÄ‚ñà ‚ñÄ‚ñÄ‚ñà ‚ñÑ‚ñà
#
#              ¬© Copyright 2022
#
#             developed by @anon97945
#
#          https://t.me/apodiktum_modules
#
# üîí Licensed under the GNU GPLv3
# üåê https://www.gnu.org/licenses/gpl-3.0.html

# meta developer: @apodiktum_modules

# scope: hikka_only
# scope: hikka_min 1.1.28

import logging

import collections  # for MigratorClass
import hashlib  # for MigratorClass
import copy     # for MigratorClass

from telethon.tl.types import Message, User, Channel
from telethon.errors import MessageIdInvalidError
from io import BytesIO

from .. import loader, utils

logger = logging.getLogger(__name__)


def get_link(user: User or Channel) -> str:
    """Get link to object (User or Channel)"""
    return (
        f"tg://user?id={user.id}"
        if isinstance(user, User)
        else (
            f"tg://resolve?domain={user.username}"
            if getattr(user, "username", None)
            else ""
        )
    )


@loader.tds
class ApodiktumPMLogMod(loader.Module):
    """
    Logs PMs to a group/channel
    """
    strings = {
        "name": "Apo PMLogger",
        "developer": "@anon97945",
        "_cfg_bots": "Whether to log bots or not.",
        "_cfg_log_group": "Group or channel ID where to send the PMs.",
        "_cfg_loglist": "Add telegram id's to log them.",
        "_cfg_selfdestructive": "Whether selfdestructive media should be logged or not. This violates TG TOS!",
        "_cfg_whitelist": "Whether the list is a for excluded(True) or included(False) chats.",
        "_cfg_cst_auto_migrate": "Wheather to auto migrate defined changes on startup.",
        "_cfg_cst_auto_migrate_log": "Wheather log auto migrate as info(True) or debug(False).",
        "_cfg_cst_auto_migrate_debug": "Wheather log debug messages of auto migrate.",
    }

    strings_de = {
        "_cfg_bots": "Ob Bots geloggt werden sollen oder nicht.",
        "_cfg_log_group": "Gruppen- oder Kanal-ID, an die die PMs gesendet werden sollen.",
        "_cfg_loglist": "F√ºgen Sie Telegram-IDs hinzu, um sie zu protokollieren.",
        "_cfg_selfdestructive": "Ob selbstzerst√∂rende Medien geloggt werden sollen oder nicht. Dies verst√∂√üt gegen die TG TOS!",
        "_cfg_whitelist": "Ob die Liste f√ºr ausgeschlossene (Wahr) oder eingeschlossene (Falsch) Chats ist.",
        "_cmd_doc_cpmlog": "Dadurch wird die Konfiguration f√ºr das Modul ge√∂ffnet.",
    }

    strings_ru = {
        "_cfg_bots": "–†–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞—Ç—å –±–æ—Ç–æ–≤ –∏–ª–∏ –Ω–µ—Ç",
        "_cfg_log_group": "–ê–π–¥–∏ –≥—Ä—É–ø–ø—ã –∏–ª–∏ –∫–∞–Ω–∞–ª–∞ –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –ª–∏—á–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π.",
        "_cfg_loglist": "–î–æ–±–∞–≤—å—Ç–µ –∞–π–¥–∏ Telegram, —á—Ç–æ–±—ã –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞—Ç—å –∏—Ö",
        "_cfg_selfdestructive": "–î–æ–ª–∂–Ω—ã –ª–∏ —Å–∞–º–æ—É–Ω–∏—á—Ç–æ–∂–∞—é—â–∏–µ—Å—è –º–µ–¥–∏–∞—Ñ–∞–π–ª—ã —Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞—Ç—å—Å—è –∏–ª–∏ –Ω–µ—Ç. –≠—Ç–æ –Ω–∞—Ä—É—à–∞–µ—Ç ¬´–£—Å–ª–æ–≤–∏—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è Telegram¬ª (ToS)",
        "_cfg_whitelist": "–Ø–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å–ø–∏—Å–æ–∫ –¥–ª—è –∏—Å–∫–ª—é—á—ë–Ω–Ω—ã—Ö (True) –∏–ª–∏ –≤–∫–ª—é—á—ë–Ω–Ω—ã—Ö —á–∞—Ç–æ–≤ (False).",
        "_cmd_doc_cpmlog": "–≠—Ç–æ –æ—Ç–∫—Ä–æ–µ—Ç –∫–æ–Ω—Ñ–∏–≥ –¥–ª—è –º–æ–¥—É–ª—è.",
    }

    def __init__(self):
        self._ratelimit = []
        self.config = loader.ModuleConfig(
            loader.ConfigValue(
                "log_bots",
                "False",
                doc=lambda: self.strings("_cfg_bots"),
                validator=loader.validators.Boolean(),
            ),
            loader.ConfigValue(
                "log_group",
                doc=lambda: self.strings("_cfg_log_group"),
                validator=loader.validators.TelegramID(),
            ),
            loader.ConfigValue(
                "log_list",
                doc=lambda: self.strings("_cfg_loglist"),
                validator=loader.validators.Series(
                    validator=loader.validators.TelegramID()
                ),
            ),
            loader.ConfigValue(
                "log_self_destr",
                "False",
                doc=lambda: self.strings("_cfg_selfdestructive"),
                validator=loader.validators.Boolean(),
            ),
            loader.ConfigValue(
                "whitelist",
                "false",
                doc=lambda: self.strings("_cfg_whitelist"),
                validator=loader.validators.Boolean(),
            ),
            loader.ConfigValue(
                "auto_migrate",
                True,
                doc=lambda: self.strings("_cfg_cst_auto_migrate"),
                validator=loader.validators.Boolean(),
            ),  # for MigratorClass
            loader.ConfigValue(
                "auto_migrate_log",
                True,
                doc=lambda: self.strings("_cfg_cst_auto_migrate_log"),
                validator=loader.validators.Boolean(),
            ),  # for MigratorClass
            loader.ConfigValue(
                "auto_migrate_debug",
                False,
                doc=lambda: self.strings("_cfg_cst_auto_migrate_debug"),
                validator=loader.validators.Boolean(),
            ),  # for MigratorClass
        )

    async def client_ready(self, client, db):
        self._db = db
        self._id = (await client.get_me(True)).user_id
        # MigratorClass
        self._migrator = MigratorClass()  # MigratorClass define
        await self._migrator.init(client, db, self, self.__class__.__name__, self.strings("name"), self.config["auto_migrate_log"], self.config["auto_migrate_debug"])  # MigratorClass Initiate
        await self._migrator.auto_migrate_handler(self.config["auto_migrate"])
        # MigratorClass

    async def get_media(self, message: Message):
        file = (
            BytesIO((await self.fast_download(message.media)).getvalue())
        )
        file.seek(0)
        return file

    async def cpmlogcmd(self, message: Message):
        """
        This will open the config for the module.
        """
        name = self.strings("name")
        await self.allmodules.commands["config"](
            await utils.answer(message, f"{self.get_prefix()}config {name}")
        )

    async def watcher(self, message: Message):
        if not message.is_private or not isinstance(message, Message):
            return
        pmlog_whitelist = self.config["whitelist"]
        pmlog_bot = self.config["log_bots"]
        pmlog_group = self.config["log_group"]
        pmlog_destr = self.config["log_self_destr"]
        chat = await message.get_chat()
        if chat.bot and not pmlog_bot or chat.id == self._id or pmlog_group is None:
            return
        chatidindb = utils.get_chat_id(message) in (self.config["logs_list"] or [])
        if pmlog_whitelist and chatidindb or not pmlog_whitelist and not chatidindb:
            return
        if pmlog_group:
            if chat.username:
                name = f"@{chat.username}"
            elif chat.last_name:
                name = f"{chat.first_name} {chat.last_name}"
            else:
                name = chat.first_name
            user_id = str(chat.id)
            user_url = get_link(chat.id)
            link = "Chat: <a href='" + user_url + "'>" + name + "</a>\nID: " + user_id
            try:
                await message.forward_to(pmlog_group)
                await message.client.send_message(pmlog_group, link)
                return
            except MessageIdInvalidError:
                if not message.file or not pmlog_destr:
                    return
                file = BytesIO()
                caption = message.text + "\n\n" + link
                file = await self.get_media(message)
                file.name = message.file.name or f"{message.file.media.id}{message.file.ext}"
                file.seek(0)
                await message.client.send_file(pmlog_group, file, force_document=True, caption=caption)


class MigratorClass():
    """
    # ‚ñÑ‚ñÄ‚ñà ‚ñà‚ñÑ ‚ñà ‚ñà‚ñÄ‚ñà ‚ñà‚ñÑ ‚ñà ‚ñà‚ñÄ‚ñà ‚ñÄ‚ñÄ‚ñà ‚ñà‚ñÄ‚ñà ‚ñà ‚ñà ‚ñà‚ñÄ
    # ‚ñà‚ñÄ‚ñà ‚ñà ‚ñÄ‚ñà ‚ñà‚ñÑ‚ñà ‚ñà ‚ñÄ‚ñà ‚ñÄ‚ñÄ‚ñà   ‚ñà ‚ñÄ‚ñÄ‚ñà ‚ñÄ‚ñÄ‚ñà ‚ñÑ‚ñà
    #
    #              ¬© Copyright 2022
    #
    #             developed by @anon97945
    #
    #          https://t.me/apodiktum_modules
    #
    # üîí Licensed under the GNU GPLv3
    # üåê https://www.gnu.org/licenses/gpl-3.0.html
    """

    strings = {
        "_log_doc_migrated_db": "Migrated {} database of {} -> {}:\n{}",
        "_log_doc_migrated_cfgv_val": "[Dynamic={}] Migrated default config value:\n{} -> {}",
        "_log_doc_no_dynamic_migration": "No module config found. Did not dynamic migrate:\n{{{}: {}}}",
        "_log_doc_migrated_db_not_found": "`{}` database not found. Did not migrate {} -> {}",
    }

    changes = {
    }

    def __init__(self):
        self._ratelimit = []

    async def init(
        self,
        client: "TelegramClient",  # type: ignore
        db: "Database",  # type: ignore
        modules: str,  # type: ignore
        classname: str,  # type: ignore
        name: str,  # type: ignore
        log: bool = False,  # type: ignore
        debug: bool = False,  # type: ignore
    ):
        self._client = client
        self._db = db
        self._classname = classname
        self._name = name
        self.modules = modules
        self.log = log
        self.debug = debug
        self.hashs = []
        self.hashs = self._db.get(self._classname, "hashs", [])
        self._migrate_to = list(self.changes)[-1] if self.changes else None

    async def migrate(self, log: bool = False, debug: bool = False):
        self.log = log
        self.debug = debug
        logger.error(f"Log: {self.log} | Debug: {self.debug}")
        if self._migrate_to is not None:
            self.hashs = self._db.get(self._classname, "hashs", [])

            migrate = await self.check_new_migration()
            full_migrated = await self.full_migrated()
            if migrate:
                await self._logger(f"Open migrations: {migrate}", self.debug)
                if await self._migrator_func():
                    await self._logger("Migration done.", self.debug)
                    return True
            elif not full_migrated:
                await self.force_set_hashs()
                await self._logger(f"Open migrations: {migrate} | Forcehash done: {self.hashs}", self.debug)
                return False
            else:
                await self._logger(f"Open migrations: {migrate} | Skip migration.", self.debug)
                return False
            return False
        await self._logger("No changes in `changes` dictionary found.", self.debug)
        return False

    async def auto_migrate_handler(self, auto_migrate: bool = False):
        if self._migrate_to is not None:
            self.hashs = self._db.get(self._classname, "hashs", [])
            migrate = await self.check_new_migration()
            full_migrated = await self.full_migrated()
            if auto_migrate and migrate:
                await self._logger(f"Open migrations: {migrate} | auto_migrate: {auto_migrate}", self.debug)
                if await self._migrator_func():
                    await self._logger("Migration done.", self.debug)
                    return
            elif not auto_migrate and not full_migrated:
                await self.force_set_hashs()
                await self._logger(f"Open migrations: {migrate} | auto_migrate: {auto_migrate} | Forcehash done: {self.hashs}", self.debug)
                return
            else:
                await self._logger(f"Open migrations: {migrate} | auto_migrate: {auto_migrate} | Skip migrate_handler.", self.debug)
                return
        await self._logger("No changes in `changes` dictionary found.", self.debug)
        return

    async def force_set_hashs(self):
        await self._set_missing_hashs()
        return True

    async def check_new_migration(self):
        chash = hashlib.md5(self._migrate_to.encode('utf-8')).hexdigest()
        return chash not in self.hashs

    async def full_migrated(self):
        full_migrated = True
        for migration in self.changes:
            chash = hashlib.md5(migration.encode('utf-8')).hexdigest()
            if chash not in self.hashs:
                full_migrated = False
        return full_migrated

    async def _migrator_func(self):
        for migration in self.changes:
            chash = hashlib.md5(migration.encode('utf-8')).hexdigest()
            if chash not in self.hashs:
                old_classname, new_classname, old_name, new_name = await self._get_names(migration)
                for category in self.changes[migration]:
                    await self._copy_config_init(migration, old_classname, new_classname, old_name, new_name, category)
                await self._set_hash(chash)
        return True

    async def _copy_config_init(self, migration, old_classname, new_classname, old_name, new_name, category):
        if category == "classname":
            if self._classname != old_classname and (old_classname in self._db.keys() and self._db[old_classname] and old_classname is not None):
                await self._logger(f"{migration} | {category} | old_value: {str(old_classname)} | new_value: {str(new_classname)}", self.debug)
                await self._copy_config(category, old_classname, new_classname, new_name)
            else:
                await self._logger(self.strings["_log_doc_migrated_db_not_found"].format(category, old_classname, new_classname))
        elif category == "name":
            await self._logger(f"{migration} | {category} | old_value: {str(old_name)} | new_value: {str(new_name)}", self.debug)
            if self._name != old_name and (old_name in self._db.keys() and self._db[old_name] and old_name is not None):
                await self._copy_config(category, old_name, new_name, new_classname)
            else:
                await self._logger(self.strings["_log_doc_migrated_db_not_found"].format(category, old_name, new_name))
        elif category == "config":
            await self._migrate_cfg_values(migration, category, new_name, new_classname)
        return

    async def _get_names(self, migration):
        for category in self.changes[migration]:
            if category == "classname":
                old_classname, new_classname = await self._get_changes(self.changes[migration][category].items())
            elif category == "name":
                old_name, new_name = await self._get_changes(self.changes[migration][category].items())
        if not new_name:
            new_name = self._name
        if not new_classname:
            new_classname = self._classname
        return old_classname, new_classname, old_name, new_name

    @staticmethod
    async def _get_changes(changes):
        old_value = None
        new_value = None
        for state, value in changes:
            if state == "old":
                old_value = value
            elif state == "new":
                new_value = value
        return old_value, new_value

    async def _migrate_cfg_values(self, migration, category, new_name, new_classname):
        if new_classname in self._db.keys() and "__config__" in self._db[new_classname]:
            if configdb := self._db[new_classname]["__config__"]:
                for cnfg_key in self.changes[migration][category]:
                    old_value, new_value = await self._get_changes(self.changes[migration][category][cnfg_key].items())
                    for key, value in configdb.items():
                        await self._logger(f"{migration} | {category} | ({{old_value: {str(old_value)}}} `==` {{new_value: {str(value)}}}) `and` {{key: {key}}} `==` {{cnfg_key: {cnfg_key}}}", self.debug)
                        if value == old_value and key == cnfg_key:
                            dynamic = False
                            self._db[new_classname]["__config__"][cnfg_key] = new_value
                            if (
                                self.modules.lookup(new_name)
                                and self.modules.lookup(new_name).config
                                and key in self.modules.lookup(new_name).config
                            ):
                                self.modules.lookup(new_name).config[cnfg_key] = new_value
                                dynamic = True
                            await self._logger(self.strings["_log_doc_migrated_cfgv_val"].format(dynamic, value, new_value))
        return

    async def _copy_config(self, category, old_name, new_name, name):
        if self._db[new_name]:
            temp_db = {new_name: copy.deepcopy(self._db[new_name])}
            self._db[new_name].clear()
            self._db[new_name] = await self._deep_dict_merge(temp_db[new_name], self._db[old_name])
            temp_db.pop(new_name)
        else:
            self._db[new_name] = copy.deepcopy(self._db[old_name])
        self._db.pop(old_name)
        await self._logger(self.strings["_log_doc_migrated_db"].format(category, old_name, new_name, self._db[new_name]))
        if category == "classname":
            await self._make_dynamic_config(name, new_name)
        if category == "name":
            await self._make_dynamic_config(new_name, name)
        return

    async def _deep_dict_merge(self, dct1, dct2, override=True) -> dict:
        merged = copy.deepcopy(dct1)
        for k, v2 in dct2.items():
            if k in merged:
                v1 = merged[k]
                if isinstance(v1, dict) and isinstance(v2, collections.Mapping):
                    merged[k] = await self._deep_dict_merge(v1, v2, override)
                elif isinstance(v1, list) and isinstance(v2, list):
                    merged[k] = v1 + v2
                elif override:
                    merged[k] = copy.deepcopy(v2)
            else:
                merged[k] = copy.deepcopy(v2)
        return merged

    async def _make_dynamic_config(self, new_name, new_classname=None):
        if new_classname is None:
            return
        if "__config__" in self._db[new_classname].keys():
            for key, value in self._db[new_classname]["__config__"].items():
                if (
                    self.modules.lookup(new_name)
                    and self.modules.lookup(new_name).config
                    and key in self.modules.lookup(new_name).config
                ):
                    self.modules.lookup(new_name).config[key] = value
                else:
                    await self._logger(self.strings["_log_doc_no_dynamic_migration"].format(key, value))
        return

    async def _set_hash(self, chash):
        self.hashs.append(chash)
        self._db.set(self._classname, "hashs", self.hashs)
        return

    async def _set_missing_hashs(self):
        for migration in self.changes:
            chash = hashlib.md5(migration.encode('utf-8')).hexdigest()
            if chash not in self.hashs:
                await self._set_hash(chash)

    async def _logger(self, log_string, debug: bool = False):
        if debug or self.log:
            return logger.info(log_string)
        return logger.debug(log_string)
